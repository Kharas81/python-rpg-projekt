{
  // Konfigurationen für verschiedene Teile des Spiels
  "game_settings": {
    "min_damage": 1,
    "base_weapon_damage": 5,
    
    // Trefferchance-Konfiguration
    "hit_chance_base": 90,       // Basis-Trefferchance in Prozent
    "hit_chance_accuracy_factor": 3,  // Multiplikator für Genauigkeitsbonus
    "hit_chance_evasion_factor": 2,   // Multiplikator für Ausweichbonus
    "hit_chance_min": 5,         // Minimale Trefferchance in Prozent
    "hit_chance_max": 95,        // Maximale Trefferchance in Prozent
    
    // XP und Level-Konfiguration
    "xp_level_base": 100,        // Basis-XP für Level 2
    "xp_level_factor": 1.5,      // Exponentielle Zunahme der XP pro Level
    
    // Ressourcenregeneration pro Runde
    "resource_regen_percent": 5  // 5% der maximal verfügbaren Ressource wird pro Runde regeneriert
  },
  
  // Logging-Konfiguration
  "logging": {
    "level": "INFO",           // Log-Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "date_format": "%Y-%m-%d %H:%M:%S",
    "file": "game.log"         // Pfad zur Log-Datei
  },
  
  // Reinforcement Learning (RL) Konfiguration
  "rl_settings": {
    "observation_space": {
      "include_allies": true,   // Verbündete in Beobachtungen einbeziehen
      "include_enemies": true,  // Gegner in Beobachtungen einbeziehen
      "max_allies": 4,          // Maximale Anzahl an Verbündeten in der Beobachtung
      "max_enemies": 6          // Maximale Anzahl an Gegnern in der Beobachtung
    },
    "reward_settings": {
      "victory_reward": 100.0,  // Belohnung für einen Sieg
      "defeat_penalty": -50.0,  // Strafe für eine Niederlage
      "damage_dealt_factor": 0.1, // Multiplikator für verursachten Schaden
      "damage_taken_factor": -0.1, // Multiplikator für erlittenen Schaden
      "healing_factor": 0.2,    // Multiplikator für durchgeführte Heilung
      "self_damage_factor": -0.5, // Multiplikator für selbst zugefügten Schaden
      "time_penalty": -0.1      // Zeitstrafe pro Runde (um schnelle Lösungen zu fördern)
    },
    "training": {
      "learning_rate": 0.0003,  // Lernrate für den RL-Algorithmus
      "batch_size": 64,         // Batch-Größe für Training
      "buffer_size": 100000,    // Größe des Replay-Puffers
      "exploration_fraction": 0.1, // Anteil der Gesamtschritte für Exploration-Verringerung
      "exploration_initial": 1.0, // Anfangswert für Explorations-Epsilon
      "exploration_final": 0.05, // Endwert für Explorations-Epsilon
      "gamma": 0.99            // Discount-Faktor für zukünftige Belohnungen
    }
  }
}
